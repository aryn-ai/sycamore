# Sycamore Query Evaluation tool

This tool can be used to evaluate the query planning and answering capabilities
of Sycamore Query against a given dataset and set of queries. This is a wrapper
around the `sycamore.query.client.SycamoreQueryClient` class that reads a
configuration from an input YAML file, and writes results to an output YAML file.

## Input file format

The input file format is YAML and is defined by the `queryeval.types.QueryEvalInputFile`
class. The following is a minimal example of the input file format:

```yaml
# General configuration options. Each of these can be specified
# on the command line as well.
config:
    # The OpenSearch index to use.
    index: const_ntsb

# The list of queries to run. Each has a query and an expected
# result, which can be either a string, or a list of dictionaries,
# with each element of the list representing a Sycamore Document
# expected to be returned by the query.
queries:
    - query: "How many incidents were there in 2023?"
      expected: "There were 10 incidents in 2023."
    - query: "How many incidents occurred in bad weather?"
      expected: "7 incidents occurred in bad weather."
```

Examples of input files can be found in the `data/` directory.

## Output file format

The output file format is YAML and is defined by the `queryeval.types.QueryEvalResultsFile`
type. Depending on the configuration options used when run, the output file may
contain one or more of the following:
    * Query plans generated by the Sycamore Query Planner.
    * Query results produced by running these query plans.
    * Accuracy and quality metrics calculated from the query results.

The idea is that each of these stages of the evaluation can be run independently, and
the results from previous stages can be used as input to the next stage.

## Running the tool

First, run `poetry install` in this directory to install all dependencies.

You can get a full list of options by running:

```bash
$ poetry run python queryeval/main.py --help
```

To generate query plans and run all of the resulting queries:

```bash
$ poetry run python queryeval/main.py --outfile results.yaml data/ntsb-mini.yaml run
```

To only generate query plans:

```bash
$ poetry run python queryeval/main.py --outfile results.yaml data/ntsb-mini.yaml plan
```

Note that the query plans generated during the `plan` phase are saved to the results
file, so if you use `run` after `plan` with the same `--outfile` option set, the query plans
will be reused. You can force regeneration of the query plans using the `--overwrite` option.

## Specifying the schema

By default, the data schema will be fetched from the provided OpenSearch index.
However, the schema can be specified manually by setting the `data_schema` field in the
input file. Each field in the schema has two entries: the type of the field, and
a list of example values. For example:

```yaml
data_schema:

  properties.entity.accidentNumber:
    # The type of the field.
    - str
    # A list of example values.
    - ["CEN23LAO80", "DCA23LA133", "CEN23LA086", "ERA23LA168", "CEN23LA097"]

  properties.entity.aircraftDamage:
    - str
    # You can also specify individual examples as list entries on their own line.
    - - Destroyed
      - None
      - Substantial
```

## Useful flags

Use the `--query-cache-path` and `--llm-cache-path` flags to specify caches for intermediate
query results and LLM results, respectively. This can save a substantial amount of time and
LLM cost if you are doing repeated evaluations, however, be aware that stale cache entries
may affect your results.

Use `--dry-run` to avoid performing any planning, queries, or writing results. This is useful
to test if your config file format is correct.

Use `--logfile` to write detailed logs of the evaluation process to a file.



