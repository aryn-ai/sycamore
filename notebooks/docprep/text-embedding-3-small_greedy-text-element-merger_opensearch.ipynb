{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install sycamore-ai[opensearch]\n",
        "# DocPrep code uses the Sycamore document ETL library: https://github.com/aryn-ai/sycamore "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!apt-get install poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pyarrow.fs\n",
        "import sycamore\n",
        "import json\n",
        "import os\n",
        "from opensearchpy import OpenSearch\n",
        "from sycamore.functions.tokenizer import OpenAITokenizer\n",
        "from sycamore.llms import OpenAIModels, OpenAI\n",
        "from sycamore.transforms import COALESCE_WHITESPACE\n",
        "from sycamore.transforms.merge_elements import GreedyTextElementMerger\n",
        "from sycamore.transforms.partition import ArynPartitioner\n",
        "from sycamore.transforms.embed import OpenAIEmbedder\n",
        "from sycamore.materialize_config import MaterializeSourceMode\n",
        "from sycamore.utils.pdf_utils import show_pages\n",
        "from sycamore.transforms.summarize_images import SummarizeImages\n",
        "from sycamore.context import ExecMode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# It's best to store API keys in a configuration file or set them as environment variables.  \n",
        "# For quick testing, you can define them here:\n",
        "#\n",
        "# os.environ[\"ARYN_API_KEY\"] = \"YOUR_ARYN_API_KEY\"\n",
        "# os.environ[\"OS_USER_NAME\"] = \"YOUR_OPENSEARCH_USER_NAME\"\n",
        "# os.environ[\"OS_PASSWORD\"] = \"YOUR_OPENSEARCH_PASSWORD\"\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sycamore uses lazy execution for efficiency, so the ETL pipeline will only execute when running cells with specific functions.\n",
        "  \n",
        "paths = [\"s3://aryn-public/ntsb/59.pdf\"]\n",
        "# Configure your AWS credentials here if the bucket is private\n",
        "fsys = pyarrow.fs.S3FileSystem(region=\"us-east-1\", anonymous=True)\n",
        "# Initialize the Sycamore context\n",
        "ctx = sycamore.init(ExecMode.LOCAL)\n",
        "# Set the embedding model and its parameters\n",
        "model_name = \"text-embedding-3-small\"\n",
        "max_tokens = 8191\n",
        "dimensions = 1536\n",
        "# Initialize the tokenizer\n",
        "tokenizer = OpenAITokenizer(model_name)\n",
        "\n",
        "ds = (\n",
        "    ctx.read.binary(paths, binary_format=\"pdf\", filesystem=fsys)\n",
        "    # Partition and extract tables and images\n",
        "    .partition(partitioner=ArynPartitioner(\n",
        "        threshold=\"auto\",\n",
        "        use_ocr=True,\n",
        "        extract_table_structure=True,\n",
        "        extract_images=True\n",
        "    ))\n",
        "    # Use materialize to cache output. If changing upstream code or input files, change setting from USE_STORED to RECOMPUTE to create a new cache.\n",
        "    .materialize(path=\"./materialize/partitioned\", source_mode=MaterializeSourceMode.USE_STORED)\n",
        "    # Merge elements into larger chunks\n",
        "    .merge(merger=GreedyTextElementMerger(\n",
        "      tokenizer=tokenizer,  max_tokens=max_tokens, merge_across_pages=False\n",
        "    ))\n",
        "    # Split elements that are too big to embed\n",
        "    .split_elements(tokenizer=tokenizer, max_tokens=max_tokens)\n",
        ")\n",
        "\n",
        "ds.execute()\n",
        "\n",
        "# Display the first 3 pages after chunking\n",
        "show_pages(ds, limit=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedded_ds = (\n",
        "    # Copy document properties to each Document's sub-elements\n",
        "    ds.spread_properties([\"path\", \"entity\"])\n",
        "    # Convert all Elements to Documents\n",
        "    .explode() \n",
        "    # Embed each Document. You can change the embedding model. Make your target vector index matches this number of dimensions.\n",
        "    .embed(embedder=OpenAIEmbedder(model_name=model_name))\n",
        ")\n",
        "# To know more about docset transforms, please visit https://sycamore.readthedocs.io/en/latest/sycamore/transforms.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "index_name = \"docprep-test-index-2\"\n",
        "# Configure the OpenSearch client arguments\n",
        "os_client_args = {\n",
        "    \"hosts\": [{\"host\": \"search-docprep-test-heb7e2427c7cxbwqscj6pwgx2y.us-east-1.es.amazonaws.com\", \"port\": 443}],\n",
        "    \"http_auth\": (os.getenv(\"OS_USER_NAME\"), os.getenv(\"OS_PASSWORD\")),\n",
        "    \"verify_certs\": False,\n",
        "    \"use_ssl\": True,\n",
        "}\n",
        "\n",
        "# Configure the settings and mappings for the OpenSearch index\n",
        "index_settings = {\n",
        "    \"body\": {\n",
        "        \"settings\": {\n",
        "            \"index.knn\": True,\n",
        "        },\n",
        "        \"mappings\": {\n",
        "            \"properties\": {\n",
        "                \"embedding\": {\n",
        "                    \"type\": \"knn_vector\",\n",
        "                    \"dimension\": dimensions,\n",
        "                    \"method\": {\"name\": \"hnsw\", \"engine\": \"faiss\"},\n",
        "                },\n",
        "            },\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "# Write the docset to the specified OpenSearch index\n",
        "embedded_ds.write.opensearch(\n",
        "    os_client_args=os_client_args,\n",
        "    index_name=index_name,\n",
        "    index_settings=index_settings,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify data has been loaded using DocSet Query to retrieve chunks\n",
        "query_docs = ctx.read.opensearch(os_client_args=os_client_args, index_name=index_name, query={\"query\": {\"match_all\": {}}})\n",
        "query_docs.show(show_embedding=False)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
