{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7ee170b-42da-4e86-a47a-38bfc399b0d5",
   "metadata": {},
   "source": [
    "# Workshop Notebook 4 - Analytics Queries with Sycamore\n",
    "\n",
    "In the previous tutorial we answered several questions using RAG, however there were some patterns that RAG could not \n",
    "get, as the context window is too small (and LLMs aren't great at counting).\n",
    "\n",
    "For a refresher, here are the questions:\n",
    "\n",
    "0. In the Broadcom earnings call, what details did the CEO, Hock Tan, discuss about the VMware acqusition?\n",
    "1. What was the revenue in the Q2 AirBnB earnings call?\n",
    "2. List all the speakers in the MongoDB Q4 2024 earnings call.\n",
    "3. List all the speakers in the Broadcom Q4 2024 earnings call.\n",
    "4. How many customers did MongoDB have at the end of the Q1 2024 quarter?\n",
    "5. What was the first PLTR earnings call where Anduril is mentioned?\n",
    "6. List all the companies that mentioned inflation and give me a count of the number of times each of the companies mentioned inflation.\n",
    "7. Summarize how the VMWare acquisition contributed to revenue changes for Broadcom quarter over quarter.\n",
    "8. Summarize how Intuitâ€™s latest AI powered platform, Intuit Assist is being integrated through its products. Give me a quarter by quarter break down of the progress. \n",
    "9. Summarize all the mergers and acquisitions that happened in 2024 and give a breakdown of how each acquisition impacted earnings.\n",
    "10. Summarize how AI integration is progressing across each company's products. Give me a quarter by quarter break down of the progress per company and overall.\n",
    "\n",
    "We were able to answer up to question 5 with RAG, although as discussed question 5 is a little dangerous. With more data we are not necessarily guaranteed to get\n",
    "the correct answer. Accordingly, let's pick up from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e48625f-8683-4e35-9571-d39ac3c792fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last notebook we wrote our docset id to a file to pick up here.\n",
    "with open(\"docset_id\", \"r\") as f:\n",
    "    docset_id = f.read()\n",
    "\n",
    "print(docset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb0a190-dec6-4ffd-9e41-3bfb1ca95020",
   "metadata": {},
   "source": [
    "### Question 5: What was the first PLTR earnings call where Anduril is mentioned?\n",
    "\n",
    "Correct answer: Q3 2024 (November 4)\n",
    "\n",
    "As shown previously, this question can be answered by RAG, but this is mostly due to the fact that our dataset is rather small.\n",
    "What we'd actually like to do is \n",
    "\n",
    "1. get all the records mentioning the acquisition\n",
    "2. sort them by date\n",
    "3. return the first one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518f63a1-e2c0-4247-acf0-156d2e2082db",
   "metadata": {},
   "source": [
    "That looks like a simple enough plan. Let's implement it with sycamore! We'll start by reading the DocSet from Aryn.\n",
    "\n",
    "Quiz: We'll be reading this docset from Aryn a bunch. What can we do to cache a local copy to speed this up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d4ac09-8b1b-4642-8b6e-6baef9d2d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sycamore\n",
    "from sycamore import MaterializeSourceMode\n",
    "from sycamore.data import Element, Document\n",
    "context = sycamore.init()\n",
    "\n",
    "read_me_seymoure = context.read.aryn(docset_id = docset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a249360-c1d8-469f-b08b-e6da3da0c5e9",
   "metadata": {},
   "source": [
    "The documents come out with an \"_original_elements\" property which contains a copy of the elements. We use this in the UI to render bounding boxes of elements on the \n",
    "documents (circumventing any chunking) but for our purposes this is a load of crap so we'll add a transform to remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f666d9-09e7-4d70-9949-be41ce8e777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_original_elements(doc: Document) -> Document:\n",
    "    doc.properties.pop(\"_original_elements\", None)\n",
    "    return doc\n",
    "    \n",
    "cleaned_docset = read_me_seymoure.map(remove_original_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c8881a-abdf-4679-8166-9f720477b38e",
   "metadata": {},
   "source": [
    "Now we'll actually answer the question. We'll need to flesh out the plan from above a little bit:\n",
    "\n",
    "1. Filter to only Palantir documents\n",
    "2. Filter out any elements that don't contain the string 'anduril'\n",
    "3. Filter out any documents that now contain zero elements\n",
    "4. Parse the date property (The llm generates a string, but we'd like a `DateTime` object to sort by)\n",
    "5. Sort by date\n",
    "6. Take the first document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f193c94-9ad1-4dd1-8319-9850f3a4d09c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sycamore.transforms import DateTimeStandardizer\n",
    "\n",
    "palantir_docset_sorted = (\n",
    "    cleaned_docset\n",
    "    .filter(lambda doc: doc.properties['entity']['company_ticker'] == 'PLTR')\n",
    "    .filter_elements(lambda elt: \"anduril\" in (elt.text_representation or \"\").lower())\n",
    "    .filter(lambda doc: len(doc.elements) > 0)\n",
    "    .map(lambda doc: DateTimeStandardizer.standardize(doc, key_path = [\"properties\",\"entity\",\"date\"]))\n",
    "    .sort(descending=False, field=\"properties.entity.dateTime\")\n",
    ")\n",
    "answer5_sycamore = palantir_docset_sorted.take(1)[0].properties['entity']['day']\n",
    "print(answer5_sycamore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3968d5be",
   "metadata": {},
   "source": [
    "### Question 6: List all the companies that mentioned inflation and give me a count of the number of times each of the companies mentioned inflation.\n",
    "\n",
    "Simple RAG cannot answer this question. I might be wrong, I guess, but I couldn't get it to work. And I think any RAG solution\n",
    "that does work would be very unnatural. Let's see what this looks like with sycamore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd0cefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "question6 = \"List all the companies that mentioned inflation and give me a count of the number of times each of the companies mentioned inflation.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e96ebe",
   "metadata": {},
   "source": [
    "First off, we'll want to operate on elements, not documents, since we would like to count the number of inflation mentions in each document.\n",
    "Doing this with sycamore is actually quite simple, although I tend to avoid it where possible as it makes the data model harder to reason about.\n",
    "Remember: Each member of a DocSet is a Document, and each Document contains several Elements. We're about to make sycamore treat each Element as\n",
    "a Document.\n",
    "\n",
    "The `docset.explode()` transform turns every Element into a top-level Document. However, it keeps the original top-level Documents as husks of their\n",
    "former selves (they contain no elements). Accordingly, we'll throw in this filter at the end to get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771f0245",
   "metadata": {},
   "outputs": [],
   "source": [
    "element_docset = cleaned_docset.explode().filter(lambda doc: \"parent_id\" in doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d589a9",
   "metadata": {},
   "source": [
    "Next we ask an LLM whether each element-now-document mentions inflation, keeping only the ones that do.\n",
    "We will be left with a DocSet full of quotes that mention inflation, so we can group them by company and\n",
    "then count, using the `groupby_count` transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f056b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sycamore.llms.prompts.default_prompts import LlmFilterMessagesJinjaPrompt\n",
    "from sycamore.llms.llms import LLMMode\n",
    "from sycamore.llms.openai import OpenAI, OpenAIModels\n",
    "from sycamore.functions.tokenizer import OpenAITokenizer\n",
    "\n",
    "llm = OpenAI(OpenAIModels.GPT_4O)\n",
    "tk = OpenAITokenizer(model_name=OpenAIModels.GPT_4O.value.name)\n",
    "\n",
    "inflation_mentions_ds = element_docset.llm_filter(\n",
    "    llm=llm,\n",
    "    new_field=\"inflation_mentioned_confidence\",\n",
    "    prompt = LlmFilterMessagesJinjaPrompt.fork(filter_question=\"Does this text mention inflation?\", use_elements=False),\n",
    "    tokenizer = tk,\n",
    "    max_tokens = 80_000,\n",
    ").groupby_count('properties.entity.company_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88886980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the return of the rich table\n",
    "import rich\n",
    "inflation_table = rich.table.Table(title=\"inflation_mentions\")\n",
    "inflation_table.add_column(\"company\")\n",
    "inflation_table.add_column(\"mentions\")\n",
    "\n",
    "counts = [(d.properties['count'], d.properties['key']) for d in inflation_mentions_ds.take_all()]\n",
    "for c, k in sorted(counts):\n",
    "    inflation_table.add_row(k, str(c))\n",
    "\n",
    "rich.print(inflation_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609e8ff3-2c87-4f9c-833d-12e7999e47d8",
   "metadata": {},
   "source": [
    "## Question 9: Summarize all the mergers and acquisitions that happened in 2024 and give a breakdown of how each acquisition impacted earnings.\n",
    "\n",
    "Correct answer: A summary of all the mergers and acquisitions. I ain't writing that out.\n",
    "\n",
    "Plan:\n",
    "\n",
    "1. Filter elements by whether \"merger\" or \"acquisition\" is in the text\n",
    "2. Summarize everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9034a8b1-0d7b-46c9-8047-90590c24798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, a filter_elements. This is fairly simple\n",
    "from sycamore.data import Element\n",
    "\n",
    "def filter_mna(elt: Element) -> bool:\n",
    "    return \"acquisition\" in elt.text_representation.lower() or \"merger\" in elt.text_representation.lower() \n",
    "\n",
    "mna_filtered_ds = cleaned_docset.filter_elements(filter_mna)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d467364-aabd-473a-898e-414fda51d2a0",
   "metadata": {},
   "source": [
    "## Summarize\n",
    "\n",
    "Sycamore exports a function called `summarize_data` which attempts to summarize an entire DocSet. You can think of this as similar to a RAG operator\n",
    "except it works on data larger than the context window might allow (by heirarchically summarizing summaries). To call it, pass in a docset and a \n",
    "Summarizer like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb772c3-bea1-432f-972e-0e060de01ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sycamore.transforms.summarize import MultiStepDocumentSummarizer, EtCetera\n",
    "from sycamore.query.execution.operations import summarize_data\n",
    "from sycamore.functions.tokenizer import OpenAITokenizer\n",
    "from sycamore.llms.llms import LLMMode\n",
    "\n",
    "\n",
    "oaitk = OpenAITokenizer(OpenAIModels.GPT_4O.value.name, max_tokens=100_000)\n",
    "\n",
    "# Some parameters that will go into the prompt - the question you want the llm to answer, and a description of\n",
    "# the data being provided\n",
    "question = \"For each of the companies mentioned please summarize the impact of mergers and acquisitions on earnings.\"\n",
    "data_desc = \"Acquisition Earnings\"\n",
    "\n",
    "# Construct the summarizer:\n",
    "# llm_mode tells it to make its llm calls asynchronously\n",
    "# fields is a list of fields to include for each document. a list terminating with the sentinel value EtCetera means\n",
    "#     \"all fields, but any that were specified go first\"\n",
    "# tokenizer is needed to determine how many documents can fit in a batch.\n",
    "summarizer = MultiStepDocumentSummarizer(\n",
    "    llm=llm, \n",
    "    llm_mode=LLMMode.ASYNC, \n",
    "    question=question, \n",
    "    data_description=data_desc, \n",
    "    fields=[EtCetera],\n",
    "    tokenizer=oaitk\n",
    ")\n",
    "\n",
    "# Summarize:\n",
    "summary = summarize_data(\n",
    "    llm=llm,\n",
    "    question=question,\n",
    "    data_description=data_desc,\n",
    "    input_data=[mna_filtered_ds],\n",
    "    docset_summarizer=summarizer\n",
    ")\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a47b9b-6de8-4132-9d65-323d1b8b90c9",
   "metadata": {},
   "source": [
    "## Question 10: Summarize how AI integration is progressing across each company's products.\n",
    "\n",
    "Plan:\n",
    "1. llm_map to get how AI is being integrated into the company's products\n",
    "2. llm_filter \"Is artificial intelligence being discussed?\"\n",
    "3. summarize_data: pointing `fields` at the date, company name, and integration summary properties\n",
    "\n",
    "See if you can get this one to work. Good Luck!\n",
    "\n",
    "I've started it with an example of what the llm_map might look like. I'm now realizing llm_map is new\n",
    "to this tutorial. llm_map takes a prompt, llm, and output_field, parametrizes the prompt with each\n",
    "document and calls the llm, and puts the llm response in `doc.properties[output_field]`\n",
    "\n",
    "More documentation on prompts is [here](https://sycamore.readthedocs.io/en/stable/sycamore/APIs/prompts.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4860ef4-6c38-435f-bdd5-98f18d990b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sycamore.llms.prompts.prompts import JinjaPrompt\n",
    "\n",
    "# JinjaPrompt parametrizes a prompt using the Jinja templating system. Each template gets a reference\n",
    "#   to `doc` which is the document being parametrized.\n",
    "# There is also a JinjaElementPrompt which gets references to `elt` and `doc` (the element and the\n",
    "#   element's parent document)\n",
    "ai_integration_prompt = JinjaPrompt(\n",
    "    system = \"You are a banana\",\n",
    "    user = \"\"\"\n",
    "    You are given a transcript of an earnings call for {{ doc.properties['entity']['company_name'] }}.\n",
    "    Please generate a summary of how AI is being integrated into the company's products.\n",
    "\n",
    "    Transcript:\n",
    "    {% for elt in doc.elements %}\n",
    "    {{ elt.text_representation }}\n",
    "    {% endfor %}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "cleaned_docset.llm_map(prompt=ai_integration_prompt, llm=llm, output_field=\"ai_integration_summary\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
