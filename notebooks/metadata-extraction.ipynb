{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fc8f90b-c30d-49f5-9a53-3cb7b0bd7b34",
   "metadata": {},
   "source": [
    "##### In this example, we will write the output of the Sycamore job from pdf in S3 to a target vector and keyword indexes in OpenSearch.\n",
    "\n",
    "##### The Aryn Partitioner in this job is configured to use the Aryn Partitioning Service to provide fast, GPU-powered performance. Go to [aryn.ai/sign-up ](aryn.ai/sign-up) to get a free API key for the service. This is the recommended configuration.\n",
    "\n",
    "##### You can also run the Aryn Partitioner locally by setting `use_partitioning_service` to `False`. Though you can use CPU to run the Aryn Partitioner, it is recommended to use an NVIDIA GPU for good performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sycamore.data import Document\n",
    "from sycamore.functions import HuggingFaceTokenizer\n",
    "from sycamore.llms import OpenAI, OpenAIModels\n",
    "from sycamore.transforms.extract_schema import OpenAISchemaExtractor, OpenAIPropertyExtractor\n",
    "from sycamore.transforms.extract_entity import OpenAIEntityExtractor\n",
    "from sycamore.transforms.merge_elements import GreedyTextElementMerger\n",
    "from sycamore.transforms.partition import ArynPartitioner\n",
    "import sycamore\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6639325-d421-4d64-aa4e-a44c006df5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sycamore.utils.aryn_config import ArynConfig, _DEFAULT_PATH\n",
    "assert ArynConfig.get_aryn_api_key() != \"\", f\"Unable to find aryn API key.  Looked in {_DEFAULT_PATH}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cb1a15-5a04-44b9-96ca-9416c869528c",
   "metadata": {},
   "source": [
    "if the above assertion fails, you can either set the environment variable ARYN_API_KEY and restart jupyter\n",
    "or make a yaml file at the specified path in the assertion error that looks like:\n",
    "\n",
    "```\n",
    "aryn_token: \"YOUR-ARYN-API-KEY\"\n",
    "```\n",
    "\n",
    "It is unsafe, but if neither of those options work, you can put it in this notebook with\n",
    "```\n",
    "import os\n",
    "os.environ[\"ARYN_API_KEY\"] = \"UNSAFE-ARYN-API-KEY-LOCATION\" \n",
    "```\n",
    "\n",
    "but beware that it is easy to accidentally commit the notebook file and have it include your key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "def convert_timestamp(doc: Document) -> Document:\n",
    "    if \"dateAndTime\" not in doc.properties['entity'] and \"dateTime\" not in doc.properties['entity']:\n",
    "        return doc\n",
    "    raw_date: str = doc.properties['entity'].get('dateAndTime') or doc.properties['entity'].get('dateTime')\n",
    "    raw_date = raw_date.replace(\"Local\", \"\")\n",
    "    parsed_date = parser.parse(raw_date, fuzzy=True)\n",
    "    extracted_date = parsed_date.date()\n",
    "    doc.properties['entity']['day'] = extracted_date.isoformat()\n",
    "    if parsed_date.utcoffset():\n",
    "        doc.properties['entity']['isoDateTime'] = parsed_date.isoformat()\n",
    "    else:\n",
    "        doc.properties['entity']['isoDateTime'] = parsed_date.isoformat() + \"Z\"\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_path = \"s3://aryn-public/ntsb/\"\n",
    "partition_materialize_path = \"s3://aryn-public/materialize/notebooks/partition-ntsb/2024-10-11\"\n",
    "\n",
    "llm = OpenAI(OpenAIModels.GPT_3_5_TURBO.value)\n",
    "tokenizer = HuggingFaceTokenizer(\"thenlper/gte-small\")\n",
    "\n",
    "ctx = sycamore.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docset = (\n",
    "    ctx.read.binary(s3_path, binary_format=\"pdf\")\n",
    "    .partition(partitioner=ArynPartitioner())\n",
    "    .materialize(path=partition_materialize_path, source_mode=sycamore.MATERIALIZE_USE_STORED) # avoid expensive re-partitioning step\n",
    "    )\n",
    "docset.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "docset = (\n",
    "    docset\n",
    "    .extract_batch_schema(schema_extractor=OpenAISchemaExtractor(\"FlightAccidentReport\", llm=llm, num_of_elements=35))\n",
    "    .extract_properties(property_extractor=OpenAIPropertyExtractor(llm=llm, num_of_elements=35))\n",
    "    .merge(GreedyTextElementMerger(tokenizer, 300))\n",
    "    .map(convert_timestamp)\n",
    "    .materialize(\"tmp/metadata-extraction/post-convert-timestamp\", source_mode=sycamore.MATERIALIZE_USE_STORED) # avoid recomputation after take\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_docs = docset.take()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_docs[0].properties['_schema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_docs[0].properties['entity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in sample_docs:\n",
    "    print(f\"Path: {d.properties['path']}\")\n",
    "    for k in [\"dateTime\", \"day\", \"aircraft\", \"location\"]:\n",
    "            print(f\"{k: <25} {d.properties['entity'].get(k, 'None')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sycamore.transforms.embed import SentenceTransformerEmbedder\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"/.dockerenv\"):\n",
    "    opensearch_host = \"opensearch\"\n",
    "    print(\"Assuming we are in a Sycamore Jupyter container, using opensearch for OpenSearch host\")\n",
    "else:\n",
    "    opensearch_host = \"localhost\"\n",
    "    print(\"Assuming we are running outside of a container, using localhost for OpenSearch host\")\n",
    "\n",
    "index = \"ntsb_demoindex0\"\n",
    "os_client_args = {\n",
    "    \"hosts\": [{\"host\": opensearch_host, \"port\": 9200}],\n",
    "    \"http_compress\": True,\n",
    "    \"http_auth\": (\"admin\", \"admin\"),\n",
    "    \"use_ssl\": True,\n",
    "    \"verify_certs\": False,\n",
    "    \"ssl_assert_hostname\": False,\n",
    "    \"ssl_show_warn\": False,\n",
    "    \"timeout\": 120,\n",
    "}\n",
    "\n",
    "index_settings = {\n",
    "    \"body\": {\n",
    "        \"settings\": {\n",
    "            \"index.knn\": True,\n",
    "            \"number_of_shards\": 5,\n",
    "            \"number_of_replicas\": 1\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"embedding\": {\n",
    "                  \"dimension\": 384,\n",
    "                  \"method\": {\n",
    "                    \"engine\": \"faiss\",\n",
    "                    \"space_type\": \"l2\",\n",
    "                    \"name\": \"hnsw\",\n",
    "                    \"parameters\": {}\n",
    "                  },\n",
    "                  \"type\": \"knn_vector\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "docset = (\n",
    "    docset\n",
    "    .spread_properties([\"entity\", \"path\"])\n",
    "    .explode()\n",
    "    .sketch()\n",
    "    .embed(embedder=SentenceTransformerEmbedder(batch_size=100, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "docset.write.opensearch(\n",
    "    os_client_args=os_client_args,\n",
    "    index_name=index,\n",
    "    index_settings=index_settings,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
