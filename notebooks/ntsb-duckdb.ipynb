{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.fs\n",
    "from ray.data import ActorPoolStrategy\n",
    "import sycamore\n",
    "from sycamore.functions.tokenizer import HuggingFaceTokenizer\n",
    "from sycamore.llms import OpenAIModels, OpenAI\n",
    "from sycamore.transforms import COALESCE_WHITESPACE\n",
    "from sycamore.transforms.merge_elements import MarkedMerger\n",
    "from sycamore.transforms.partition import SycamorePartitioner\n",
    "from sycamore.transforms.extract_schema import OpenAISchemaExtractor, OpenAIPropertyExtractor\n",
    "from sycamore.transforms.embed import SentenceTransformerEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sycamore.data.document import Document\n",
    "from dateutil import parser\n",
    "def convert_timestamp(doc: Document) -> Document:\n",
    "    if \"dateAndTime\" not in doc.properties['entity'] and \"dateTime\" not in doc.properties['entity']:\n",
    "        return doc\n",
    "    raw_date: str = doc.properties['entity'].get('dateAndTime') or doc.properties['entity'].get('dateTime')\n",
    "    raw_date = raw_date.replace(\"Local\", \"\")\n",
    "    parsed_date = parser.parse(raw_date, fuzzy=True)\n",
    "    extracted_date = parsed_date.date()\n",
    "    doc.properties['entity']['day'] = extracted_date.day\n",
    "    doc.properties['entity']['month'] = extracted_date.month\n",
    "    doc.properties['entity']['year'] = extracted_date.year\n",
    "    if parsed_date.utcoffset():\n",
    "        doc.properties['entity']['dateTime'] = parsed_date.isoformat()\n",
    "    else:\n",
    "        doc.properties['entity']['dateTime'] = parsed_date.isoformat() + \"Z\"\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"s3://aryn-public/ntsb/\"]\n",
    "fsys = pyarrow.fs.S3FileSystem(region=\"us-east-1\", anonymous=True)\n",
    "\n",
    "llm = OpenAI(OpenAIModels.GPT_3_5_TURBO.value)\n",
    "tokenizer = HuggingFaceTokenizer(\"thenlper/gte-small\")\n",
    "\n",
    "ctx = sycamore.init()\n",
    "\n",
    "ds = (\n",
    "    ctx.read.binary(paths, binary_format=\"pdf\", filesystem=fsys)\n",
    "    # Parition with the sycamore partitioner, pulling out tables and images. ActorPoolStrategy(size=3) works best on my particular hardware\n",
    "    # but your mileage may vary depending on your RAM.\n",
    "    .partition(partitioner=SycamorePartitioner(extract_table_structure=True, extract_images=True), compute=ActorPoolStrategy(size=3))\n",
    "    # Get rid of spurious whitespace charaters\n",
    "    .regex_replace(COALESCE_WHITESPACE)\n",
    "    # Automatically determine a schema of additional metadata to extract from documents\n",
    "    .extract_batch_schema(schema_extractor=OpenAISchemaExtractor(\"FlightAccidentReport\", llm=llm, num_of_elements=35))\n",
    "    # Extract the metadata specified by that schema\n",
    "    .extract_properties(property_extractor=OpenAIPropertyExtractor(llm=llm, num_of_elements=35))\n",
    "    # Merge elements into larger chunks\n",
    "    .mark_bbox_preset(tokenizer=tokenizer)\n",
    "    .merge(merger=MarkedMerger())\n",
    "    # Convert extracted timestamps to better-structured form using the function above\n",
    "    .map(convert_timestamp)\n",
    "    # Copy document properties to each document's sub-elements\n",
    "    .spread_properties([\"path\", \"entity\"])\n",
    "    # Split elements that are too big to embed\n",
    "    .split_elements(tokenizer=tokenizer, max_tokens=512)\n",
    "    # Convert all Elements to Documents\n",
    "    .explode()\n",
    "    # Generate a series of hashes to represent each document. For use with near-duplicate detection\n",
    "    .sketch()\n",
    "    # Embed each document\n",
    "    .embed(embedder=SentenceTransformerEmbedder(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", batch_size=100))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 14:11:45,761\tWARNING util.py:560 -- The argument ``compute`` is deprecated in Ray 2.9. Please specify argument ``concurrency`` instead. For more information, see https://docs.ray.io/en/master/data/transforming-data.html#stateful-transforms.\n",
      "2024-07-02 14:11:45,762\tWARNING util.py:560 -- The argument ``compute`` is deprecated in Ray 2.9. Please specify argument ``concurrency`` instead. For more information, see https://docs.ray.io/en/master/data/transforming-data.html#stateful-transforms.\n",
      "2024-07-02 14:11:45,768\tWARNING util.py:560 -- The argument ``compute`` is deprecated in Ray 2.9. Please specify argument ``concurrency`` instead. For more information, see https://docs.ray.io/en/master/data/transforming-data.html#stateful-transforms.\n",
      "2024-07-02 14:11:45,774\tINFO streaming_executor.py:112 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-07-01_12-05-17_251742_53329/logs/ray-data\n",
      "2024-07-02 14:11:45,774\tINFO streaming_executor.py:113 -- Execution plan of Dataset: InputDataBuffer[Input] -> ActorPoolMapOperator[ReadBinary->Map(BinaryScan._to_document)->MapBatches(BaseMapTransformCallable___wrap)] -> ActorPoolMapOperator[MapBatches(regex_replace)->MapBatches(BaseMapTransformCustom__Extract)] -> ActorPoolMapOperator[MapBatches(extract_properties)->MapBatches(sort_by_page_bbox)->MapBatches(mark_drop_tiny)->MapBatches(mark_drop_header_and_footer)->MapBatches(mark_break_page)->MapBatches(mark_break_by_column)->MapBatches(mark_break_by_tokens)->MapBatches(merge_elements)->MapBatches(convert_timestamp)->MapBatches(spread_properties)->MapBatches(split_doc)->MapBatches(explode)->MapBatches(sketcher)->MapBatches(SentenceTransformerEmbedder)->MapBatches(BaseMapTransformCallable__duckdb_write_documents)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60920b5ec11424bad7f9ca638b81ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadBinary->Map(BinaryScan._to_document)->MapBatches(BaseMapTransformCallable___wrap) 1:   0%|          | 0/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349c35e9edf842fb81c53dbf0261c067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(regex_replace)->MapBatches(BaseMapTransformCustom__Extract) 2:   0%|          | 0/65 [00:00<?, ?i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff18ca19906f4cd9a90b66c2df88034c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(extract_properties)->MapBatches(sort_by_page_bbox)->MapBatches(mark_drop_tiny)->MapBatches(mark_d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef13368afea4b23b289dd08e1c6bc6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 14:11:56,466\tERROR streaming_executor_state.py:449 -- An exception was raised from a task of operator \"ReadBinary->Map(BinaryScan._to_document)->MapBatches(BaseMapTransformCallable___wrap)\". Dataset execution will now abort. To ignore this exception and continue, set DataContext.max_errored_blocks.\n",
      "2024-07-02 14:11:56,474\tWARNING actor_pool_map_operator.py:292 -- To ensure full parallelization across an actor pool of size 3, the Dataset should consist of at least 3 distinct blocks. Consider increasing the parallelism when creating the Dataset.\n",
      "2024-07-02 14:11:56,477\tWARNING actor_pool_map_operator.py:292 -- To ensure full parallelization across an actor pool of size 1, the Dataset should consist of at least 1 distinct blocks. Consider increasing the parallelism when creating the Dataset.\n",
      "2024-07-02 14:11:56,480\tWARNING actor_pool_map_operator.py:292 -- To ensure full parallelization across an actor pool of size 1, the Dataset should consist of at least 1 distinct blocks. Consider increasing the parallelism when creating the Dataset.\n"
     ]
    },
    {
     "ename": "RayTaskError(UserCodeException)",
     "evalue": "\u001b[36mray::ReadBinary->Map(BinaryScan._to_document)->MapBatches(BaseMapTransformCallable___wrap)()\u001b[39m (pid=70168, ip=127.0.0.1, actor_id=db1f3d3cbef323e4f1ea395d01000000, repr=MapWorker(ReadBinary->Map(BinaryScan._to_document)->MapBatches(BaseMapTransformCallable___wrap)))\nAttributeError: 'SycamorePartitioner' object has no attribute '_use_cache'\n\nThe above exception was the direct cause of the following exception:\n\n\u001b[36mray::ReadBinary->Map(BinaryScan._to_document)->MapBatches(BaseMapTransformCallable___wrap)()\u001b[39m (pid=70168, ip=127.0.0.1, actor_id=db1f3d3cbef323e4f1ea395d01000000, repr=MapWorker(ReadBinary->Map(BinaryScan._to_document)->MapBatches(BaseMapTransformCallable___wrap)))\n  File \"/Users/karansampath/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/ray/data/_internal/planner/plan_udf_map_op.py\", line 110, in fn\n    return ray.data._cached_fn(item, *fn_args, **fn_kwargs)\n  File \"/Users/karansampath/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/ray/data/_internal/execution/util.py\", line 78, in __call__\n    return future.result()\n  File \"/Users/karansampath/miniforge3/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n    return self.__get_result()\n  File \"/Users/karansampath/miniforge3/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/Users/karansampath/miniforge3/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/Users/karansampath/Desktop/Repos/sycamore/lib/sycamore/sycamore/transforms/base.py\", line 172, in ray_callable\n    args = _noneOr(self._args, tuple())\n  File \"/Users/karansampath/Desktop/Repos/sycamore/lib/sycamore/sycamore/transforms/base.py\", line 230, in _process_ray\n    outputs = f(docs)\n  File \"/Users/karansampath/Desktop/Repos/sycamore/lib/sycamore/sycamore/transforms/base.py\", line 172, in <lambda>\n    args = _noneOr(self._args, tuple())\n  File \"/Users/karansampath/Desktop/Repos/sycamore/lib/sycamore/sycamore/transforms/map.py\", line 49, in _wrap\n    return [f(d, *args, **kwargs) for d in docs]\n  File \"/Users/karansampath/Desktop/Repos/sycamore/lib/sycamore/sycamore/transforms/map.py\", line 49, in <listcomp>\n    return [f(d, *args, **kwargs) for d in docs]\n  File \"/Users/karansampath/Desktop/Repos/sycamore/lib/sycamore/sycamore/utils/time_trace.py\", line 136, in wrapper\n    return f(*args, **kwargs)\n  File \"/Users/karansampath/Desktop/Repos/sycamore/lib/sycamore/sycamore/transforms/partition.py\", line 482, in partition\n    raise RuntimeError(f\"SycamorePartitioner Error processing {path}\") from e\nRuntimeError: SycamorePartitioner Error processing s3://aryn-public/ntsb/0.pdf\n\nThe above exception was the direct cause of the following exception:\n\n\u001b[36mray::ReadBinary->Map(BinaryScan._to_document)->MapBatches(BaseMapTransformCallable___wrap)()\u001b[39m (pid=70168, ip=127.0.0.1, actor_id=db1f3d3cbef323e4f1ea395d01000000, repr=MapWorker(ReadBinary->Map(BinaryScan._to_document)->MapBatches(BaseMapTransformCallable___wrap)))\n  File \"/Users/karansampath/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/ray/data/_internal/execution/operators/actor_pool_map_operator.py\", line 403, in submit\n    yield from _map_task(\n  File \"/Users/karansampath/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_operator.py\", line 419, in _map_task\n    for b_out in map_transformer.apply_transform(iter(blocks), ctx):\n  File \"/Users/karansampath/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_transformer.py\", line 392, in __call__\n    for data in iter:\n  File \"/Users/karansampath/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_transformer.py\", line 134, in _udf_timed_iter\n    output = next(input)\n  File \"/Users/karansampath/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_transformer.py\", line 236, in __call__\n    yield from self._batch_fn(input, ctx)\n  File \"/Users/karansampath/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/ray/data/_internal/planner/plan_udf_map_op.py\", line 208, in transform_fn\n    res = fn(batch)\n  File \"/Users/karansampath/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/ray/data/_internal/planner/plan_udf_map_op.py\", line 112, in fn\n    _handle_debugger_exception(e)\n  File \"/Users/karansampath/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/ray/data/_internal/planner/plan_udf_map_op.py\", line 143, in _handle_debugger_exception\n    raise UserCodeException() from e\nray.exceptions.UserCodeException",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError(UserCodeException)\u001b[0m           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m persistent_db \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdemo.db\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m persistent_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdemo_table\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mduckdb\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdb_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersistent_db\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersistent_table\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Repos/sycamore/lib/sycamore/sycamore/writer.py:418\u001b[0m, in \u001b[0;36mduckdb\u001b[0;34m(self, db_url, table_name, execute, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m target_params \u001b[38;5;241m=\u001b[39m DuckDBTargetParams(db_url\u001b[38;5;241m=\u001b[39mdb_url, table_name\u001b[38;5;241m=\u001b[39mtable_name)\n\u001b[1;32m    416\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompute\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ActorPoolStrategy(size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    417\u001b[0m ddb \u001b[38;5;241m=\u001b[39m DuckDBWriter(\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplan,\n\u001b[1;32m    419\u001b[0m     client_params\u001b[38;5;241m=\u001b[39mclient_params,\n\u001b[1;32m    420\u001b[0m     target_params\u001b[38;5;241m=\u001b[39mtarget_params,\n\u001b[1;32m    421\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mduckdb_write_documents\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    423\u001b[0m )\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m execute:\n\u001b[1;32m    425\u001b[0m     ddb\u001b[38;5;241m.\u001b[39mexecute()\u001b[38;5;241m.\u001b[39mmaterialize()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/ray/data/dataset.py:4542\u001b[0m, in \u001b[0;36mDataset.materialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4523\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute and materialize this dataset into object store memory.\u001b[39;00m\n\u001b[1;32m   4524\u001b[0m \n\u001b[1;32m   4525\u001b[0m \u001b[38;5;124;03mThis can be used to read all blocks into memory. By default, Dataset\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4539\u001b[0m \u001b[38;5;124;03m    A MaterializedDataset holding the materialized data blocks.\u001b[39;00m\n\u001b[1;32m   4540\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4541\u001b[0m copy \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m, _deep_copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, _as\u001b[38;5;241m=\u001b[39mMaterializedDataset)\n\u001b[0;32m-> 4542\u001b[0m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce_read\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   4544\u001b[0m blocks \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39m_plan\u001b[38;5;241m.\u001b[39m_snapshot_blocks\n\u001b[1;32m   4545\u001b[0m blocks_with_metadata \u001b[38;5;241m=\u001b[39m blocks\u001b[38;5;241m.\u001b[39mget_blocks_with_metadata() \u001b[38;5;28;01mif\u001b[39;00m blocks \u001b[38;5;28;01melse\u001b[39;00m []\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/ray/data/exceptions.py:84\u001b[0m, in \u001b[0;36momit_traceback_stdout.<locals>.handle_trace\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m logger\u001b[38;5;241m.\u001b[39mexception(\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull stack trace:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extra\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhide\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;129;01mnot\u001b[39;00m log_to_stdout}\n\u001b[1;32m     82\u001b[0m )\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_user_code_exception:\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mSystemException\u001b[39;00m()\n",
      "\u001b[0;31mRayTaskError(UserCodeException)\u001b[0m: \u001b[36mray::ReadBinary->Map(BinaryScan._to_document)->MapBatches(BaseMapTransformCallable___wrap)()\u001b[39m (pid=70168, ip=127.0.0.1, actor_id=db1f3d3cbef323e4f1ea395d01000000, repr=MapWorker(ReadBinary->Map(BinaryScan._to_document)->MapBatches(BaseMapTransformCallable___wrap)))\nAttributeError: 'SycamorePartitioner' object has no attribute '_use_cache'\n\nThe above exception was the direct cause of the following exception:\n\n\u001b[36mray::ReadBinary->Map(BinaryScan._to_document)->MapBatches(BaseMapTransformCallable___wrap)()\u001b[39m (pid=70168, ip=127.0.0.1, actor_id=db1f3d3cbef323e4f1ea395d01000000, repr=MapWorker(ReadBinary->Map(BinaryScan._to_document)->MapBatches(BaseMapTransformCallable___wrap)))\n  File \"/Users/karansampath/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/ray/data/_internal/planner/plan_udf_map_op.py\", line 110, in fn\n    return ray.data._cached_fn(item, *fn_args, **fn_kwargs)\n  File \"/Users/karansampath/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/ray/data/_internal/execution/util.py\", line 78, in __call__\n    return future.result()\n  File \"/Users/karansampath/miniforge3/lib/python3.10/concurrent/futures/_base.py\", line 458, in result\n    return self.__get_result()\n  File \"/Users/karansampath/miniforge3/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/Users/karansampath/miniforge3/lib/python3.10/concurrent/futures/thread.py\", line 58, in run\n    result = self.fn(*self.args, **self.kwargs)\n  File \"/Users/karansampath/Desktop/Repos/sycamore/lib/sycamore/sycamore/transforms/base.py\", line 172, in ray_callable\n    args = _noneOr(self._args, tuple())\n  File \"/Users/karansampath/Desktop/Repos/sycamore/lib/sycamore/sycamore/transforms/base.py\", line 230, in _process_ray\n    outputs = f(docs)\n  File \"/Users/karansampath/Desktop/Repos/sycamore/lib/sycamore/sycamore/transforms/base.py\", line 172, in <lambda>\n    args = _noneOr(self._args, tuple())\n  File \"/Users/karansampath/Desktop/Repos/sycamore/lib/sycamore/sycamore/transforms/map.py\", line 49, in _wrap\n    return [f(d, *args, **kwargs) for d in docs]\n  File \"/Users/karansampath/Desktop/Repos/sycamore/lib/sycamore/sycamore/transforms/map.py\", line 49, in <listcomp>\n    return [f(d, *args, **kwargs) for d in docs]\n  File \"/Users/karansampath/Desktop/Repos/sycamore/lib/sycamore/sycamore/utils/time_trace.py\", line 136, in wrapper\n    return f(*args, **kwargs)\n  File \"/Users/karansampath/Desktop/Repos/sycamore/lib/sycamore/sycamore/transforms/partition.py\", line 482, in partition\n    raise RuntimeError(f\"SycamorePartitioner Error processing {path}\") from e\nRuntimeError: SycamorePartitioner Error processing s3://aryn-public/ntsb/0.pdf\n\nThe above exception was the direct cause of the following exception:\n\n\u001b[36mray::ReadBinary->Map(BinaryScan._to_document)->MapBatches(BaseMapTransformCallable___wrap)()\u001b[39m (pid=70168, ip=127.0.0.1, actor_id=db1f3d3cbef323e4f1ea395d01000000, repr=MapWorker(ReadBinary->Map(BinaryScan._to_document)->MapBatches(BaseMapTransformCallable___wrap)))\n  File \"/Users/karansampath/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/ray/data/_internal/execution/operators/actor_pool_map_operator.py\", line 403, in submit\n    yield from _map_task(\n  File \"/Users/karansampath/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_operator.py\", line 419, in _map_task\n    for b_out in map_transformer.apply_transform(iter(blocks), ctx):\n  File \"/Users/karansampath/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_transformer.py\", line 392, in __call__\n    for data in iter:\n  File \"/Users/karansampath/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_transformer.py\", line 134, in _udf_timed_iter\n    output = next(input)\n  File \"/Users/karansampath/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/ray/data/_internal/execution/operators/map_transformer.py\", line 236, in __call__\n    yield from self._batch_fn(input, ctx)\n  File \"/Users/karansampath/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/ray/data/_internal/planner/plan_udf_map_op.py\", line 208, in transform_fn\n    res = fn(batch)\n  File \"/Users/karansampath/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/ray/data/_internal/planner/plan_udf_map_op.py\", line 112, in fn\n    _handle_debugger_exception(e)\n  File \"/Users/karansampath/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/ray/data/_internal/planner/plan_udf_map_op.py\", line 143, in _handle_debugger_exception\n    raise UserCodeException() from e\nray.exceptions.UserCodeException"
     ]
    }
   ],
   "source": [
    "# Write to a persistent duckdb database\n",
    "# - into a specific database (as specified by url) \n",
    "# - into a specific table (as specified by table name)\n",
    "persistent_db = \"demo.db\"\n",
    "persistent_table = \"demo_table\"\n",
    "ds.write.duckdb(\n",
    "    db_url=persistent_db,\n",
    "    table_name=persistent_table\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We connect to the DuckDB to perform operations\n",
    "import duckdb\n",
    "data_conn = duckdb.connect(\"demo.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionException",
     "evalue": "Connection Error: Connection has already been closed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m in_memory_db \u001b[38;5;241m=\u001b[39m duckdb\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:default:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# in_memory_db.install_extension(\"vss\")\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# in_memory_db.load_extension(\"vss\")\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[43min_memory_db\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mCREATE TABLE in_memory_table (doc_id \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdoc_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;43m                      embeddings \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43membeddings\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, properties \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproperties\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;43m                      text_representation \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext_representation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, bbox \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbbox\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;43m                      shingles \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mshingles\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, type \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m in_memory_db\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mINSERT INTO in_memory_table SELECT * FROM df; \u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124m                      CREATE INDEX in_memory_table_index ON in_memory_table USING HNSW(embeddings)\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n",
      "\u001b[0;31mConnectionException\u001b[0m: Connection Error: Connection has already been closed"
     ]
    }
   ],
   "source": [
    "# DuckDB is not production ready yet for efficient Vector Similarity Search on persistent databases (https://duckdb.org/docs/extensions/vss.html), \n",
    "# so we load our data into an in-memory database for this demo. In future versions, once DuckDB productionizes this feature, there will be no more need for this code cell\n",
    "\n",
    "# Load from disk into Pandas Dataframe as an intermediate step\n",
    "df = data_conn.execute(\"SELECT * FROM demo_table\").fetchdf()\n",
    "df.dropna(subset=[\"embeddings\"],inplace=True)\n",
    "\n",
    "# Now, we load the data into an in-memory database. Notice that we specify beforehand since we need the embedding column (must be specified as a FLOAT[N] where N is specified) \n",
    "# for Vector Similarity Search using HNSW to work\n",
    "schema = {\n",
    "            \"doc_id\": \"VARCHAR\",\n",
    "            \"embeddings\": \"FLOAT[384]\",\n",
    "            \"properties\": \"MAP(VARCHAR, VARCHAR)\",\n",
    "            \"text_representation\": \"VARCHAR\",\n",
    "            \"bbox\": \"DOUBLE[]\",\n",
    "            \"shingles\": \"BIGINT[]\",\n",
    "            \"type\": \"VARCHAR\",\n",
    "        }\n",
    "in_memory_db = duckdb.connect(\":default:\")\n",
    "# in_memory_db.install_extension(\"vss\")\n",
    "# in_memory_db.load_extension(\"vss\")\n",
    "in_memory_db.execute(f\"\"\"CREATE TABLE in_memory_table (doc_id {schema.get('doc_id')},\n",
    "                      embeddings {schema.get('embeddings')}, properties {schema.get('properties')}, \n",
    "                      text_representation {schema.get('text_representation')}, bbox {schema.get('bbox')}, \n",
    "                      shingles {schema.get('shingles')}, type {schema.get('type')})\"\"\"\n",
    "    )\n",
    "in_memory_db.execute(\"\"\"INSERT INTO in_memory_table SELECT * FROM df; \n",
    "                      CREATE INDEX in_memory_table_index ON in_memory_table USING HNSW(embeddings)\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karansampath/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# For queries, let's define an embedding function for the question that helps us easily compare the two vectors and generate optimal results // Run NN search\n",
    "from sentence_transformers import SentenceTransformer\n",
    "minilm = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "class Embedder():\n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "    \n",
    "    def embed_query(self, question):\n",
    "        v = self.llm.encode(question).tolist()\n",
    "        return v\n",
    "\n",
    "embedder = Embedder(minilm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────────┬──────────────────────┬────────────────────────────────────────────────────────────────────────┐\n",
      "│        doc_id        │ text_representation  │                               properties                               │\n",
      "│       varchar        │       varchar        │                         map(varchar, varchar)                          │\n",
      "├──────────────────────┼──────────────────────┼────────────────────────────────────────────────────────────────────────┤\n",
      "│ 73f87ba9-ff4e-4d75…  │ The National Trans…  │ {score=0.8915606737136841, page_numbers=[1], page_number=1, path=s3:…  │\n",
      "│ 06b31736-b0ed-4c57…  │ The National Trans…  │ {score=0.8774372339248657, page_numbers=[1], page_number=1, path=s3:…  │\n",
      "│ d701d8a7-b5fa-4a8f…  │ The National Trans…  │ {score=0.7743222713470459, page_numbers=[1], page_number=1, path=s3:…  │\n",
      "│ 36e85e87-85b7-4261…  │ The National Trans…  │ {score=0.7248827219009399, page_numbers=[1], page_number=1, path=s3:…  │\n",
      "│ 0918cf95-4cbb-452c…  │ The National Trans…  │ {score=0.7322630286216736, page_numbers=[1], page_number=1, path=s3:…  │\n",
      "│ cd5d8027-b01b-49ab…  │ The National Trans…  │ {score=0.7365314364433289, page_numbers=[1], page_number=1, path=s3:…  │\n",
      "│ 7a30f2ad-ebfe-457e…  │ The National Trans…  │ {score=0.6194686889648438, page_numbers=[1], page_number=1, path=s3:…  │\n",
      "│ 028ac479-d388-4320…  │ The National Trans…  │ {score=0.8677337765693665, page_numbers=[1], page_number=1, path=s3:…  │\n",
      "│ 2988b1ab-2eb1-4e64…  │ The National Trans…  │ {score=0.8568803071975708, page_numbers=[1], page_number=1, path=s3:…  │\n",
      "│ 3ffb4b09-71ad-43b3…  │ The National Trans…  │ {score=0.8405874371528625, page_numbers=[1], page_number=1, path=s3:…  │\n",
      "├──────────────────────┴──────────────────────┴────────────────────────────────────────────────────────────────────────┤\n",
      "│ 10 rows                                                                                                    3 columns │\n",
      "└──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let us now see the performance of the ANN HNSW search using DuckDB // array_distance is the nn lookup\n",
    "q = \"What automobile type is the most accident prone?\"\n",
    "in_memory_db.sql(f\"SELECT doc_id, text_representation, properties FROM in_memory_table ORDER BY array_distance(embeddings, {embedder.embed_query(q)}::FLOAT[384]) LIMIT 10;\")\n",
    "# Pretty print tables\n",
    "# text representation --> print one cell out (of the top result). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌──────────────────────┬──────────────────────┬────────────────────────────────────────────────────────────────────────┐\n",
       "│        doc_id        │ text_representation  │                               properties                               │\n",
       "│       varchar        │       varchar        │                         map(varchar, varchar)                          │\n",
       "├──────────────────────┼──────────────────────┼────────────────────────────────────────────────────────────────────────┤\n",
       "│ 3c82fabc-9f99-4dfe…  │ Airport Informatio…  │ {score=0.7310920357704163, page_numbers=[5], page_number=5, path=s3:…  │\n",
       "│ 8f3d0214-9de3-48c3…  │ Airport Informatio…  │ {score=0.702387809753418, page_numbers=[5], page_number=5, path=s3:/…  │\n",
       "│ 1c6083df-00a8-484e…  │ Airport Informatio…  │ {score=0.6993858218193054, page_numbers=[5], page_number=5, path=s3:…  │\n",
       "│ b10638a0-2ea2-4d23…  │ Airport Informatio…  │ {score=0.7263772487640381, page_numbers=[5], page_number=5, path=s3:…  │\n",
       "│ c0594fed-b67a-44b9…  │ Airport Informatio…  │ {score=0.7013193368911743, page_numbers=[5], page_number=5, path=s3:…  │\n",
       "│ b1896c98-e854-41cd…  │ Airport Informatio…  │ {score=0.7164381146430969, page_numbers=[5], page_number=5, path=s3:…  │\n",
       "│ 4da07493-8808-4b92…  │ Airport Informatio…  │ {score=0.72945636510849, page_numbers=[5], page_number=5, path=s3://…  │\n",
       "│ f2a4f9f8-fa4a-46e1…  │ Airport Informatio…  │ {score=0.7050329446792603, page_numbers=[5], page_number=5, path=s3:…  │\n",
       "│ 8a2faffe-4059-460d…  │ Airport Informatio…  │ {score=0.7286437153816223, page_numbers=[5], page_number=5, path=s3:…  │\n",
       "│ d0437fc8-0da0-4611…  │ Airport Informatio…  │ {score=0.7291507720947266, page_numbers=[5], page_number=5, path=s3:…  │\n",
       "├──────────────────────┴──────────────────────┴────────────────────────────────────────────────────────────────────────┤\n",
       "│ 10 rows                                                                                                    3 columns │\n",
       "└──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us now see the performance of the ANN HNSW search using DuckDB \n",
    "q = \"Traffic Statistics\"\n",
    "in_memory_db.sql(f\"SELECT doc_id, text_representation, properties FROM in_memory_table ORDER BY array_distance(embeddings, {embedder.embed_query(q)}::FLOAT[384]) LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────────────┬──────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
       "│  explain_key  │                                            explain_value                                             │\n",
       "│    varchar    │                                               varchar                                                │\n",
       "├───────────────┼──────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
       "│ physical_plan │ ┌───────────────────────────┐\\n│         PROJECTION        │\\n│   ─ ─ ─ ─ ─ ─ ─ ─ ─ ─ ─   │\\n│    …  │\n",
       "└───────────────┴──────────────────────────────────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also see the performance of the DuckDB query and check the index is being used by using the in-built visualization below \n",
    "q = \"What automobile type is the most accident prone?\"\n",
    "in_memory_db.sql(f\"EXPLAIN SELECT doc_id, text_representation, properties FROM in_memory_table ORDER BY array_distance(embeddings, {embedder.embed_query(q)}::FLOAT[384]) LIMIT 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌──────────────────────┬──────────────────────┬────────────────────────────────────────────────────────────────────────┐\n",
       "│        doc_id        │ text_representation  │                               properties                               │\n",
       "│       varchar        │       varchar        │                         map(varchar, varchar)                          │\n",
       "├──────────────────────┼──────────────────────┼────────────────────────────────────────────────────────────────────────┤\n",
       "│ 73f87ba9-ff4e-4d75…  │ The National Trans…  │ {score=0.8915606737136841, page_numbers=[1], page_number=1, path=s3:…  │\n",
       "│ 06b31736-b0ed-4c57…  │ The National Trans…  │ {score=0.8774372339248657, page_numbers=[1], page_number=1, path=s3:…  │\n",
       "│ d701d8a7-b5fa-4a8f…  │ The National Trans…  │ {score=0.7743222713470459, page_numbers=[1], page_number=1, path=s3:…  │\n",
       "│ 36e85e87-85b7-4261…  │ The National Trans…  │ {score=0.7248827219009399, page_numbers=[1], page_number=1, path=s3:…  │\n",
       "│ 0918cf95-4cbb-452c…  │ The National Trans…  │ {score=0.7322630286216736, page_numbers=[1], page_number=1, path=s3:…  │\n",
       "│ cd5d8027-b01b-49ab…  │ The National Trans…  │ {score=0.7365314364433289, page_numbers=[1], page_number=1, path=s3:…  │\n",
       "│ 7a30f2ad-ebfe-457e…  │ The National Trans…  │ {score=0.6194686889648438, page_numbers=[1], page_number=1, path=s3:…  │\n",
       "│ 028ac479-d388-4320…  │ The National Trans…  │ {score=0.8677337765693665, page_numbers=[1], page_number=1, path=s3:…  │\n",
       "│ 2988b1ab-2eb1-4e64…  │ The National Trans…  │ {score=0.8568803071975708, page_numbers=[1], page_number=1, path=s3:…  │\n",
       "│ 3ffb4b09-71ad-43b3…  │ The National Trans…  │ {score=0.8405874371528625, page_numbers=[1], page_number=1, path=s3:…  │\n",
       "├──────────────────────┴──────────────────────┴────────────────────────────────────────────────────────────────────────┤\n",
       "│ 10 rows                                                                                                    3 columns │\n",
       "└──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally we can build an index with other distance metrics, the default is Euclidean Distance ('l2sq'), with Cosine similarity ('cosine', 'array_cosine_simarlity') \n",
    "# and Inner Product ('ip', 'array_inner_product') also supported\n",
    "in_memory_db.execute(\"CREATE INDEX in_memory_ip_index ON in_memory_table USING HNSW(embeddings) WITH (metric = 'ip')\")\n",
    "in_memory_db.sql(f\"SELECT doc_id, text_representation, properties FROM in_memory_table ORDER BY array_inner_product(embeddings, {embedder.embed_query(q)}::FLOAT[384]) LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "CatalogException",
     "evalue": "Catalog Error: Column with name metadata already exists!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatalogException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43min_memory_db\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mALTER TABLE in_memory_table ADD COLUMN metadata VARCHAR[]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mCatalogException\u001b[0m: Catalog Error: Column with name metadata already exists!"
     ]
    }
   ],
   "source": [
    "in_memory_db.sql(f\"ALTER TABLE in_memory_table ADD COLUMN metadata VARCHAR[]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m DuckDB(connection\u001b[38;5;241m=\u001b[39min_memory_db, embedding\u001b[38;5;241m=\u001b[39membedder, id_key\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoc_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, text_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_representation\u001b[39m\u001b[38;5;124m\"\u001b[39m, vector_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m, table_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min_memory_table\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# vector_store.add_texts(['text1', 'text2'])\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mvector_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraffic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/langchain_community/vectorstores/duckdb.py:228\u001b[0m, in \u001b[0;36mDuckDB.similarity_search\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m list_cosine_similarity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduckdb\u001b[38;5;241m.\u001b[39mFunctionExpression(\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_cosine_similarity\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduckdb\u001b[38;5;241m.\u001b[39mColumnExpression(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_key),\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduckdb\u001b[38;5;241m.\u001b[39mConstantExpression(embedding),\n\u001b[1;32m    216\u001b[0m )\n\u001b[1;32m    217\u001b[0m docs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_table\u001b[38;5;241m.\u001b[39mselect(\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;241m*\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;241m.\u001b[39mfetchdf()\n\u001b[1;32m    227\u001b[0m )\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    229\u001b[0m     Document(\n\u001b[1;32m    230\u001b[0m         page_content\u001b[38;5;241m=\u001b[39mdocs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text_key][idx],\n\u001b[1;32m    231\u001b[0m         metadata\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    232\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mjson\u001b[38;5;241m.\u001b[39mloads(docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m][idx]),\n\u001b[1;32m    233\u001b[0m             \u001b[38;5;66;03m# using underscore prefix to avoid conflicts with user metadata keys\u001b[39;00m\n\u001b[1;32m    234\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSIMILARITY_ALIAS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: docs[SIMILARITY_ALIAS][idx],\n\u001b[1;32m    235\u001b[0m         }\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m][idx]\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m {},\n\u001b[1;32m    238\u001b[0m     )\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(docs))\n\u001b[1;32m    240\u001b[0m ]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/langchain_community/vectorstores/duckdb.py:232\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    212\u001b[0m list_cosine_similarity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduckdb\u001b[38;5;241m.\u001b[39mFunctionExpression(\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_cosine_similarity\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduckdb\u001b[38;5;241m.\u001b[39mColumnExpression(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_key),\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mduckdb\u001b[38;5;241m.\u001b[39mConstantExpression(embedding),\n\u001b[1;32m    216\u001b[0m )\n\u001b[1;32m    217\u001b[0m docs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_table\u001b[38;5;241m.\u001b[39mselect(\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;241m*\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;241m.\u001b[39mfetchdf()\n\u001b[1;32m    227\u001b[0m )\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    229\u001b[0m     Document(\n\u001b[1;32m    230\u001b[0m         page_content\u001b[38;5;241m=\u001b[39mdocs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text_key][idx],\n\u001b[1;32m    231\u001b[0m         metadata\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m--> 232\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    233\u001b[0m             \u001b[38;5;66;03m# using underscore prefix to avoid conflicts with user metadata keys\u001b[39;00m\n\u001b[1;32m    234\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSIMILARITY_ALIAS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m: docs[SIMILARITY_ALIAS][idx],\n\u001b[1;32m    235\u001b[0m         }\n\u001b[1;32m    236\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m][idx]\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m {},\n\u001b[1;32m    238\u001b[0m     )\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(docs))\n\u001b[1;32m    240\u001b[0m ]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/json/__init__.py:339\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mbytearray\u001b[39m)):\n\u001b[0;32m--> 339\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe JSON object must be str, bytes or bytearray, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    340\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n",
      "\u001b[0;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not float"
     ]
    }
   ],
   "source": [
    "# conn = duckdb.connect(database=':memory:',\n",
    "#     config={\n",
    "#         # Sample configuration to restrict some DuckDB capabilities\n",
    "#         # List is not exhaustive. Please review DuckDB documentation.\n",
    "#             \"enable_external_access\": \"false\",\n",
    "#             \"autoinstall_known_extensions\": \"false\",\n",
    "#             \"autoload_known_extensions\": \"false\"\n",
    "#         }\n",
    "# )\n",
    "from langchain_community.vectorstores.duckdb import DuckDB\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "vector_store = DuckDB(connection=in_memory_db, embedding=embedder, id_key= \"doc_id\", text_key=\"text_representation\", vector_key=\"embeddings\", table_name=\"in_memory_table\")\n",
    "# vector_store.add_texts(['text1', 'text2'])\n",
    "result = vector_store.similarity_search('traffic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karansampath/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`run` not supported when there is not exactly one output key. Got ['answer', 'sources'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 15\u001b[0m\n\u001b[1;32m      5\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(  \n\u001b[1;32m      6\u001b[0m     openai_api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m),  \n\u001b[1;32m      7\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m'\u001b[39m,  \n\u001b[1;32m      8\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m  \n\u001b[1;32m      9\u001b[0m )  \n\u001b[1;32m     10\u001b[0m qa \u001b[38;5;241m=\u001b[39m RetrievalQAWithSourcesChain\u001b[38;5;241m.\u001b[39mfrom_chain_type(  \n\u001b[1;32m     11\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,  \n\u001b[1;32m     12\u001b[0m     chain_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstuff\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \n\u001b[1;32m     13\u001b[0m     retriever\u001b[38;5;241m=\u001b[39mvector_store\u001b[38;5;241m.\u001b[39mas_retriever()  \n\u001b[1;32m     14\u001b[0m )  \n\u001b[0;32m---> 15\u001b[0m \u001b[43mqa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:168\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     emit_warning()\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/langchain/chains/base.py:595\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convenience method for executing chain.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \n\u001b[1;32m    560\u001b[0m \u001b[38;5;124;03mThe main difference between this method and `Chain.__call__` is that this\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;124;03m        # -> \"The temperature in Boise is...\"\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;66;03m# Run at start to make sure this is possible/defined\u001b[39;00m\n\u001b[0;32m--> 595\u001b[0m _output_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_output_key\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs:\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/sycamore-ai--zTjaFUY-py3.10/lib/python3.10/site-packages/langchain/chains/base.py:543\u001b[0m, in \u001b[0;36mChain._run_output_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_output_key\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_keys) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 543\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    544\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` not supported when there is not exactly \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mone output key. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m         )\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_keys[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: `run` not supported when there is not exactly one output key. Got ['answer', 'sources']."
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI  \n",
    "from langchain.chains import RetrievalQAWithSourcesChain  \n",
    "import os\n",
    "# completion llm  \n",
    "llm = ChatOpenAI(  \n",
    "    openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),  \n",
    "    model_name='gpt-3.5-turbo',  \n",
    "    temperature=0.0  \n",
    ")  \n",
    "qa = RetrievalQAWithSourcesChain.from_chain_type(  \n",
    "    llm=llm,  \n",
    "    chain_type=\"stuff\",  \n",
    "    retriever=vector_store.as_retriever()  \n",
    ")  \n",
    "qa.run(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: If you would like to remove your database after running the code above\n",
    "try:\n",
    "    os.unlink(persistent_db)\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting {persistent_db}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sycamore-ai--zTjaFUY-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
