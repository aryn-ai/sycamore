{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, use Sycamore to process PDFs and load them into target vector and keyword indexes in OpenSearch. The dataset includes the research papers associated with the Sort Benchmark contest: https://sortbenchmark.org/\n",
    "\n",
    "The Aryn Partitioner in this job is configured to use the Aryn Partitioning Service to provide performant and high-quality document partitioning. Go to [aryn.ai/sign-up ](aryn.ai/sign-up) to get a free API key for the service. You can also configure it to run locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sycamore\n",
    "from sycamore.transforms.partition import ArynPartitioner\n",
    "from sycamore.utils.aryn_config import ArynConfig, _DEFAULT_PATH\n",
    "from sycamore.llms import OpenAIModels, OpenAI\n",
    "from sycamore.transforms.extract_entity import OpenAIEntityExtractor\n",
    "from sycamore.transforms.embed import SentenceTransformerEmbedder\n",
    "from sycamore.transforms.merge_elements import GreedySectionMerger\n",
    "from sycamore.functions.tokenizer import HuggingFaceTokenizer\n",
    "import os\n",
    "\n",
    "# S3 file path to the Sort Benchmark dataset of PDFs\n",
    "paths = \"s3://aryn-public/sort-benchmark/pdf/\"\n",
    "\n",
    "# OpenAI key and model for data extraction transform. Set the key in your environment variables or provide it here.\n",
    "openai = OpenAI(OpenAIModels.GPT_4O.value, api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Configure chunking (or merging) strategy and the number of tokens for each chunk.\n",
    "merger = GreedySectionMerger(tokenizer=HuggingFaceTokenizer(\"sentence-transformers/all-MiniLM-L6-v2\"), max_tokens=512)\n",
    "\n",
    "#Set Aryn Partitioning Service API key\n",
    "assert ArynConfig.get_aryn_api_key() != \"\", f\"Unable to find aryn API key.  Looked in {_DEFAULT_PATH}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above assertion fails, you can either set the environment variable ARYN_API_KEY and restart Jupyter\n",
    "or make a yaml file at the specified path in the assertion error that has:\n",
    "\n",
    "```\n",
    "aryn_token: \"YOUR-ARYN-API-KEY\"\n",
    "```\n",
    "\n",
    "You can also put it in this notebook with:\n",
    "```\n",
    "import os\n",
    "os.environ[\"ARYN_API_KEY\"] = \"ARYN-API-KEY-LOCATION\" \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the Sycamore pipeline up to the \"load\" step. Note that because Sycamore uses lazy execution, the pipeline will not do any processing\n",
    "#until you run the \"write\" step in a subsequent cell.\n",
    "\n",
    "# Initializing Sycamore\n",
    "context = sycamore.init()\n",
    "# Reading PDFs into a DocSet\n",
    "docset = context.read.binary(paths, binary_format=\"pdf\")\n",
    "# Partition using the Aryn Partitioning Service into structured elements. Extract tables and images. This will take a few minutes, because \n",
    "# the service is processing many pages across the document set.\n",
    "partitioned_docset = docset.partition(partitioner=ArynPartitioner(extract_images=True,  extract_table_structure=True))\n",
    "# Extract the title and author from each paper in the dataset using LLM-powered transforms\n",
    "extracted_docset = partitioned_docset.extract_entity(entity_extractor=OpenAIEntityExtractor(\"title\", llm=openai))\\\n",
    "                    .extract_entity(entity_extractor=OpenAIEntityExtractor(\"authors\", llm=openai))\n",
    "# Use the chunking strategy specified earlier to create larger chunks from groups of smaller elements in the DocSet\n",
    "chunked_docset = extracted_docset.merge(merger=merger)\n",
    "# We are using MiniLM to create vector embeddings locally for each chunk\n",
    "embedded_docset = chunked_docset.explode().embed(\n",
    "                    embedder=SentenceTransformerEmbedder(batch_size=10_000, model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set OpenSearch configuration for connector. In this example, OpenSearch is running locally.\n",
    "\n",
    "openSearch_client_args = {\n",
    "    \"hosts\": [{\"host\": \"localhost\", \"port\": 9200}],\n",
    "    \"http_compress\": True,\n",
    "    \"http_auth\": (\"admin\", \"admin\"),\n",
    "    \"use_ssl\": True,\n",
    "    \"verify_certs\": False,\n",
    "    \"ssl_assert_hostname\": False,\n",
    "    \"ssl_show_warn\": False,\n",
    "    \"timeout\": 120,\n",
    "}\n",
    "\n",
    "index_settings = {\n",
    "    \"body\": {\n",
    "        \"settings\": {\n",
    "            \"index.knn\": True,\n",
    "            \"number_of_shards\": 2,\n",
    "            \"number_of_replicas\": 1,\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"embeddings\": {\n",
    "                    \"type\": \"knn_vector\",\n",
    "                    \"dimension\": 384,\n",
    "                    \"method\": {\"name\": \"hnsw\", \"engine\": \"faiss\"},\n",
    "                },\n",
    "                \"text\": {\"type\": \"text\"},\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to OpenSearch\n",
    "\n",
    "embedded_docset.write.opensearch(\n",
    "    os_client_args=openSearch_client_args,\n",
    "    index_name=\"sort-benchmark\",\n",
    "    index_settings=index_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! You have loaded OpenSearch's vector and keyword indexes with your processed data, and you can now build your RAG or semantic search application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
