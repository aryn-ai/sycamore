{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b0f2a49-875e-4a3a-91ce-af96a7db9f50",
   "metadata": {},
   "source": [
    "##### In this example, we use EntityExtractor, create Embedding and draw Bounding Box on a pdf.\n",
    "\n",
    "##### The Aryn Partitioner in this job is configured to use the Aryn Partitioning Service to provide fast, GPU-powered performance. Go to [aryn.ai/sign-up ](aryn.ai/sign-up) to get a free API key for the service. This is the recommended configuration.\n",
    "\n",
    "##### You can also run the Aryn Partitioner locally by setting `use_partitioning_service` to `False`. Though you can use CPU to run the Aryn Partitioner, it is recommended to use an NVIDIA GPU for good performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "from IPython.display import IFrame\n",
    "from PIL import Image as PImage\n",
    "\n",
    "import sycamore\n",
    "from sycamore.data import Document\n",
    "from sycamore.transforms.embed import SentenceTransformerEmbedder\n",
    "from sycamore.transforms.extract_entity import OpenAIEntityExtractor\n",
    "from sycamore.llms import OpenAIModels, OpenAI, LLM\n",
    "from sycamore.transforms.partition import ArynPartitioner, HtmlPartitioner\n",
    "from sycamore.llms.prompts.default_prompts import TEXT_SUMMARIZER_GUIDANCE_PROMPT_CHAT\n",
    "from sycamore.transforms.summarize import Summarizer\n",
    "from sycamore.transforms.extract_table import TextractTableExtractor\n",
    "from sycamore.functions.document import split_and_convert_to_image, DrawBoxes\n",
    "from sycamore.tests.config import TEST_DIR\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49545505-6eaa-43f8-b335-12870a982f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sycamore.utils.aryn_config import ArynConfig, _DEFAULT_PATH\n",
    "assert ArynConfig.get_aryn_api_key() != \"\", f\"Unable to find aryn API key.  Looked in {_DEFAULT_PATH}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532c630d-2b4d-4e0d-aa2f-0cf07c8f68ef",
   "metadata": {},
   "source": [
    "if the above assertion fails, you can either set the environment variable ARYN_API_KEY and restart jupyter\n",
    "or make a yaml file at the specified path in the assertion error that looks like:\n",
    "\n",
    "```\n",
    "aryn_token: \"YOUR-ARYN-API-KEY\"\n",
    "```\n",
    "\n",
    "It is unsafe, but if neither of those options work, you can put it in this notebook with\n",
    "```\n",
    "import os\n",
    "os.environ[\"ARYN_API_KEY\"] = \"UNSAFE-ARYN-API-KEY-LOCATION\" \n",
    "```\n",
    "\n",
    "but beware that it is easy to accidentally commit the notebook file and have it include your key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(str(\"data/2306.07303.pdf\"), width=700, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = str(TEST_DIR / \"resources/data/pdfs/\")\n",
    "font_path = \"./EBGaramond-Bold.ttf\"\n",
    "\n",
    "openai_llm = OpenAI(OpenAIModels.GPT_3_5_TURBO.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = sycamore.init()\n",
    "pdf_docset = context.read.binary(\"data/2306.07303.pdf\", binary_format=\"pdf\")\n",
    "\n",
    "pdf_docset.show(show_binary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_func(doc: Document) -> bool:\n",
    "    return doc.properties[\"page_number\"] == 1\n",
    "\n",
    "partitioned_docset = pdf_docset.partition(partitioner=ArynPartitioner(extract_table_structure=True))\n",
    "docset = (partitioned_docset\n",
    "              .flat_map(split_and_convert_to_image)\n",
    "              .map_batch(DrawBoxes, f_constructor_args=[font_path])\n",
    "              .filter(filter_func))\n",
    "\n",
    "for doc in docset.take(2):\n",
    "    display(Image(doc.binary_representation, height=500, width=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    " title_context_template = \"\"\"\n",
    "    ELEMENT 1: Jupiter's Moons\n",
    "    ELEMENT 2: Ganymede 2020\n",
    "    ELEMENT 3: by Audi Lauper and Serena K. Goldberg. 2011\n",
    "    ELEMENT 4: From Wikipedia, the free encyclopedia\n",
    "    ELEMENT 5: Ganymede, or Jupiter III, is the largest and most massive natural satellite of Jupiter as well as in the Solar System, being a planetary-mass moon. It is the largest Solar System object without an atmosphere, despite being the only moon of the Solar System with a magnetic field. Like Titan, it is larger than the planet Mercury, but has somewhat less surface gravity than Mercury, Io or the Moon.\n",
    "    =========\n",
    "    \"Ganymede 2020\"\n",
    "\n",
    "    ELEMENT 1: FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation\n",
    "    ELEMENT 2: Tarun Kalluri * UCSD\n",
    "    ELEMENT 3: Deepak Pathak CMU\n",
    "    ELEMENT 4: Manmohan Chandraker UCSD\n",
    "    ELEMENT 5: Du Tran Facebook AI\n",
    "    ELEMENT 6: https://tarun005.github.io/FLAVR/\n",
    "    ELEMENT 7: 2 2 0 2\n",
    "    ELEMENT 8: b e F 4 2\n",
    "    ELEMENT 9: ]\n",
    "    ELEMENT 10: V C . s c [\n",
    "    ========\n",
    "    \"FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation\"\n",
    "    \n",
    "    \"\"\"\n",
    "author_context_template = \"\"\"\n",
    "    ELEMENT 1: Jupiter's Moons\n",
    "    ELEMENT 2: Ganymede 2020\n",
    "    ELEMENT 3: by Audi Lauper and Serena K. Goldberg. 2011\n",
    "    ELEMENT 4: From Wikipedia, the free encyclopedia\n",
    "    ELEMENT 5: Ganymede, or Jupiter III, is the largest and most massive natural satellite of Jupiter as well as in the Solar System, being a planetary-mass moon. It is the largest Solar System object without an atmosphere, despite being the only moon of the Solar System with a magnetic field. Like Titan, it is larger than the planet Mercury, but has somewhat less surface gravity than Mercury, Io or the Moon.\n",
    "    =========\n",
    "    Audi Laupe, Serena K. Goldberg\n",
    "\n",
    "    ELEMENT 1: FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation\n",
    "    ELEMENT 2: Tarun Kalluri * UCSD\n",
    "    ELEMENT 3: Deepak Pathak CMU\n",
    "    ELEMENT 4: Manmohan Chandraker UCSD\n",
    "    ELEMENT 5: Du Tran Facebook AI\n",
    "    ELEMENT 6: https://tarun005.github.io/FLAVR/\n",
    "    ELEMENT 7: 2 2 0 2\n",
    "    ELEMENT 8: b e F 4 2\n",
    "    ELEMENT 9: ]\n",
    "    ELEMENT 10: V C . s c [\n",
    "    ========\n",
    "    Tarun Kalluri, Deepak Pathak, Manmohan Chandraker, Du Tran\n",
    "\n",
    "    \"\"\"\n",
    "abstract_prompt_template = \"\"\"    \n",
    "    ELEMENT 1: Attention Is All You Need\n",
    "    ELEMENT 2: Ashish Vaswani∗ Google Brain avaswani@google.com\n",
    "    ELEMENT 3: Noam Shazeer∗ Google Brain noam@google.com\n",
    "    ELEMENT 4: Niki Parmar∗ Google Research nikip@google.com\n",
    "    ELEMENT 5: Jakob Uszkoreit∗ Google Research usz@google.com\n",
    "    ELEMENT 6: Llion Jones∗ Google Research llion@google.com\n",
    "    ELEMENT 7: Aidan N. Gomez∗ † University of Toronto aidan@cs.toronto.edu\n",
    "    ELEMENT 8: Łukasz Kaiser∗ Google Brain lukaszkaiser@google.com\n",
    "    ELEMENT 9: Abstract\n",
    "    ELEMENT 10: The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English- to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.\n",
    "    ========\n",
    "    \"abstract\": The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English- to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.\n",
    "    ELEMENT 1: Ray: A Distributed Framework for Emerging AI Applications\n",
    "    ELEMENT 2: Philipp Moritz∗, Robert Nishihara∗, Stephanie Wang, Alexey Tumanov, Richard Liaw, Eric Liang, Melih Elibol, Zongheng Yang, William Paul, Michael I. Jordan, Ion Stoica University of California, Berkeley\n",
    "    ELEMENT 3: 8 1 0 2\n",
    "    ELEMENT 4: Abstract\n",
    "    ELEMENT 5: and their use in prediction. These frameworks often lever- age specialized hardware (e.g., GPUs and TPUs), with the goal of reducing training time in a batch setting. Examples include TensorFlow [7], MXNet [18], and PyTorch [46]. The promise of AI is, however, far broader than classi- cal supervised learning. Emerging AI applications must increasingly operate in dynamic environments, react to changes in the environment, and take sequences of ac- tions to accomplish long-term goals [8, 43]. They must aim not only to exploit the data gathered, but also to ex- plore the space of possible actions. These broader require- ments are naturally framed within the paradigm of rein- forcement learning (RL). RL deals with learning to oper- ate continuously within an uncertain environment based on delayed and limited feedback [56]. RL-based systems have already yielded remarkable results, such as Google's AlphaGo beating a human world champion [54], and are beginning to ﬁnd their way into dialogue systems, UAVs [42], and robotic manipulation [25, 60].\n",
    "    ELEMENT 6: p e S 0 3\n",
    "    ELEMENT 7: ]\n",
    "    ELEMENT 8: C D . s c [\n",
    "    ELEMENT 9: 2 v 9 8 8 5 0 . 2 1 7 1 : v i X r a\n",
    "    ELEMENT 10: The next generation of AI applications will continuously interact with the environment and learn from these inter- actions. These applications impose new and demanding systems requirements, both in terms of performance and ﬂexibility. In this paper, we consider these requirements and present Ray—a distributed system to address them. Ray implements a uniﬁed interface that can express both task-parallel and actor-based computations, supported by a single dynamic execution engine. To meet the perfor- mance requirements, Ray employs a distributed scheduler and a distributed and fault-tolerant store to manage the system's control state. In our experiments, we demon- strate scaling beyond 1.8 million tasks per second and better performance than existing specialized systems for several challenging reinforcement learning applications.\n",
    "    ========\n",
    "    \"abstract\": The next generation of AI applications will continuously interact with the environment and learn from these inter- actions. These applications impose new and demanding systems requirements, both in terms of performance and ﬂexibility. In this paper, we consider these requirements and present Ray—a distributed system to address them. Ray implements a uniﬁed interface that can express both task-parallel and actor-based computations, supported by a single dynamic execution engine. To meet the perfor- mance requirements, Ray employs a distributed scheduler and a distributed and fault-tolerant store to manage the system's control state. In our experiments, we demon- strate scaling beyond 1.8 million tasks per second and better performance than existing specialized systems for several challenging reinforcement learning applications.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_docset = (partitioned_docset\n",
    "              .extract_entity(entity_extractor=OpenAIEntityExtractor(\"title\", llm=openai_llm, prompt_template=title_context_template))\n",
    "              .extract_entity(entity_extractor=OpenAIEntityExtractor(\"authors\", llm=openai_llm, prompt_template=author_context_template)))\n",
    "\n",
    "pdf_docset.show(show_binary = False, show_elements=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_docset = pdf_docset.explode()\n",
    "pdf_docset.show(show_binary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_docset = pdf_docset.sketch()\n",
    "pdf_docset.show(show_binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_docset = (pdf_docset\n",
    "              .embed(embedder=SentenceTransformerEmbedder(batch_size=100, model_name=\"sentence-transformers/all-MiniLM-L6-v2\")))\n",
    "pdf_docset.show(show_binary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85b7513-6745-420a-8c9c-c789bb0faf21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
